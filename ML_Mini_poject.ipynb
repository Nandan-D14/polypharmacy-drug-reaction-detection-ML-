{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceId":13357686,"sourceType":"datasetVersion","datasetId":8472587}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rdkit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T19:08:33.100670Z","iopub.execute_input":"2025-10-13T19:08:33.100962Z","iopub.status.idle":"2025-10-13T19:08:36.328954Z","shell.execute_reply.started":"2025-10-13T19:08:33.100944Z","shell.execute_reply":"2025-10-13T19:08:36.328205Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rdkit in /usr/local/lib/python3.11/dist-packages (2025.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit) (2024.2.0)\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"!pip install xgboost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T19:08:36.330659Z","iopub.execute_input":"2025-10-13T19:08:36.330924Z","iopub.status.idle":"2025-10-13T19:08:39.591782Z","shell.execute_reply.started":"2025-10-13T19:08:36.330904Z","shell.execute_reply":"2025-10-13T19:08:39.591024Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.0.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->xgboost) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->xgboost) (2024.2.0)\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\n\n# Set the data directory\nDATA_DIR = Path(\"/kaggle/input/drug-datasets/\")\n\n# List all files in the directory\nprint(\"Files in dataset:\")\nfor file in DATA_DIR.rglob(\"*\"):\n    print(f\"  {file.name} (size: {file.stat().st_size / 1e6:.1f} MB)\")\n\nprint(\"\\n--- Loading pos.csv / positive.csv ---\")\nPOS_CSV = next(DATA_DIR.rglob(\"pos.csv\"), None) or next(DATA_DIR.rglob(\"positive.csv\"), None)\nif POS_CSV:\n    pos = pd.read_csv(POS_CSV)\n    print(f\"Pos shape: {pos.shape}\")\n    print(f\"Pos columns: {list(pos.columns)}\")\n    print(\"\\nPos head (first 3 rows):\\n\", pos.head(3))\n    print(\"\\nPos describe (numeric cols):\\n\", pos.describe())\n    print(f\"Pos DrugBankID sample: {pos['DrugBankID'].iloc[0] if 'DrugBankID' in pos.columns else 'No DrugBankID col'}\")\nelse:\n    print(\"No pos/positive.csv found!\")\n\nprint(\"\\n--- Loading neg.csv / negative.csv ---\")\nNEG_CSV = next(DATA_DIR.rglob(\"neg.csv\"), None) or next(DATA_DIR.rglob(\"negative.csv\"), None)  # fixed typo from earlier\nif NEG_CSV:\n    neg = pd.read_csv(NEG_CSV)\n    print(f\"Neg shape: {neg.shape}\")\n    print(f\"Neg columns: {list(neg.columns)}\")\n    print(\"\\nNeg head (first 3 rows):\\n\", neg.head(3))\n    print(\"\\nNeg describe (numeric cols):\\n\", neg.describe())\n    print(f\"Neg DrugBankID sample: {neg['DrugBankID'].iloc[0] if 'DrugBankID' in neg.columns else 'No DrugBankID col'}\")\nelse:\n    print(\"No neg/negative.csv found!\")\n\n# Check for SMILES file\nDB_SMILES = next(DATA_DIR.rglob(\"DrugBankID2SMILES.csv\"), None) or next(DATA_DIR.rglob(\"*smile*.csv\"), None)\nif DB_SMILES:\n    print(f\"\\n--- SMILES file: {DB_SMILES.name} ---\")\n    dbmap = pd.read_csv(DB_SMILES, dtype=str, nrows=5)  # just head\n    print(f\"SMILES shape (full): unknown, head: {dbmap.shape}\")\n    print(f\"SMILES columns: {list(dbmap.columns)}\")\n    print(\"\\nSMILES head:\\n\", dbmap.head())\n\n# Check for other optional files\nSE_MAP = next(DATA_DIR.rglob(\"SE_similarity_2014Q3_2024Q3.csv\"), None)\nif SE_MAP:\n    print(f\"\\n--- SE_MAP file: {SE_MAP.name} ---\")\n    se = pd.read_csv(SE_MAP, nrows=3)\n    print(f\"Columns: {list(se.columns)}\")\n    print(se.head(3))\n\nSE_EMBED = next(DATA_DIR.rglob(\"*umls*\"), None)\nif SE_EMBED:\n    print(f\"\\n--- SE_EMBED file: {SE_EMBED.name} ---\")\n    embed = pd.read_csv(SE_EMBED, nrows=3)\n    print(f\"Shape (head): {embed.shape}\")\n    print(f\"Columns: {list(embed.columns)}\")\n    print(embed.head(3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T19:08:39.592972Z","iopub.execute_input":"2025-10-13T19:08:39.593224Z","iopub.status.idle":"2025-10-13T19:08:40.071034Z","shell.execute_reply.started":"2025-10-13T19:08:39.593202Z","shell.execute_reply":"2025-10-13T19:08:40.070255Z"}},"outputs":[{"name":"stdout","text":"Files in dataset:\n  Side_effects_unique.csv (size: 63.6 MB)\n  neg.csv (size: 12.2 MB)\n  SE_similarity_2014Q3_2024Q3.csv (size: 0.5 MB)\n  Drugbank_ID_SMILE_all_structure links.csv (size: 4.2 MB)\n  pos.csv (size: 12.0 MB)\n  DrugBankID2SMILES.csv (size: 0.9 MB)\n\n--- Loading pos.csv / positive.csv ---\nPos shape: (111072, 6)\nPos columns: ['report_id', 'SE_above_0.9', 'DrugBankID', 'hyperedge_label', 'time', 'row_index']\n\nPos head (first 3 rows):\n    report_id SE_above_0.9                                         DrugBankID  \\\n0   11809573     C0151878  ['DB01050', 'DB00555', 'DB00472', 'DB00273', '...   \n1   20088990     C0435002  ['DB06605', 'DB00834', 'DB00695', 'DB00421', '...   \n2   11703282     C0235431  ['DB01118', 'DB06228', 'DB01118', 'DB00177', '...   \n\n   hyperedge_label    time  row_index  \n0                1  2015Q4          1  \n1                1  2021Q4          2  \n2                1  2015Q4          3  \n\nPos describe (numeric cols):\n           report_id  hyperedge_label      row_index\ncount  1.110720e+05         111072.0  111072.000000\nmean   1.598583e+07              1.0   55536.500000\nstd    3.977654e+06              0.0   32063.868887\nmin    3.771344e+06              1.0       1.000000\n25%    1.264914e+07              1.0   27768.750000\n50%    1.576531e+07              1.0   55536.500000\n75%    1.886639e+07              1.0   83304.250000\nmax    2.438033e+07              1.0  111072.000000\nPos DrugBankID sample: ['DB01050', 'DB00555', 'DB00472', 'DB00273', 'DB00564', 'DB00557', 'DB00557']\n\n--- Loading neg.csv / negative.csv ---\nNeg shape: (111072, 6)\nNeg columns: ['report_id', 'SE_above_0.9', 'DrugBankID', 'hyperedge_label', 'time', 'row_index']\n\nNeg head (first 3 rows):\n    report_id SE_above_0.9                                         DrugBankID  \\\n0  11809573n     C0853776  ['DB01050', 'DB00555', 'DB00472', 'DB12805', '...   \n1  20088990n     C0221752  ['DB06605', 'DB00834', 'DB00695', 'DB00421', '...   \n2  11703282n     C0152198  ['DB06844', 'DB06228', 'DB01118', 'DB00177', '...   \n\n   hyperedge_label    time  row_index  \n0               -1  2015Q4          1  \n1               -1  2021Q4          2  \n2               -1  2015Q4          3  \n\nNeg describe (numeric cols):\n        hyperedge_label      row_index\ncount         111072.0  111072.000000\nmean              -1.0   55536.500000\nstd                0.0   32063.868887\nmin               -1.0       1.000000\n25%               -1.0   27768.750000\n50%               -1.0   55536.500000\n75%               -1.0   83304.250000\nmax               -1.0  111072.000000\nNeg DrugBankID sample: ['DB01050', 'DB00555', 'DB00472', 'DB12805', 'DB00564', 'DB00557', 'DB00557']\n\n--- SMILES file: DrugBankID2SMILES.csv ---\nSMILES shape (full): unknown, head: (5, 2)\nSMILES columns: ['drugbank_id', 'smiles']\n\nSMILES head:\n   drugbank_id smiles\n0     DB00001    NaN\n1     DB00002    NaN\n2     DB00003    NaN\n3     DB00004    NaN\n4     DB00005    NaN\n\n--- SE_MAP file: SE_similarity_2014Q3_2024Q3.csv ---\nColumns: ['SE_name_2014Q3_2024Q3', 'recommended_SE_name', 'recommended_umls_cui_from_meddra', 'cosine_similarity']\n              SE_name_2014Q3_2024Q3                     recommended_SE_name  \\\n0  17-hydroxyprogesterone increased  human chorionic gonadotropin increased   \n1         21-hydroxylase deficiency            Mineralocorticoid deficiency   \n2    ACTH stimulation test abnormal           blood corticotrophin abnormal   \n\n  recommended_umls_cui_from_meddra  cosine_similarity  \n0                         C3203514           0.647438  \n1                         C1955743           0.636915  \n2                         C0853597           0.747984  \n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# base path for your Kaggle dataset\nbase_path = \"/kaggle/input/drug-datasets\"\n\n# list all dataset files\nfiles = [\n    \"Side_effects_unique.csv\",\n    \"neg.csv\",\n    \"SE_similarity_2014Q3_2024Q3.csv\",\n    \"Drugbank_ID_SMILE_all_structure links.csv\",\n    \"pos.csv\",\n    \"DrugBankID2SMILES.csv\"\n]\n\n# loop through and read first 3 rows\nfor f in files:\n    fpath = os.path.join(base_path, f)\n    print(f\"\\n--- {f} ---\")\n    if os.path.exists(fpath):\n        try:\n            df = pd.read_csv(fpath)\n            print(df.shape)\n            print(df.head(3))\n        except Exception as e:\n            print(f\"âŒ Error reading {f}: {e}\")\n    else:\n        print(\"âŒ File not found:\", fpath)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T19:08:40.072512Z","iopub.execute_input":"2025-10-13T19:08:40.072750Z","iopub.status.idle":"2025-10-13T19:08:41.468450Z","shell.execute_reply.started":"2025-10-13T19:08:40.072732Z","shell.execute_reply":"2025-10-13T19:08:41.467754Z"}},"outputs":[{"name":"stdout","text":"\n--- Side_effects_unique.csv ---\n(7350, 770)\n  umls_cui_from_meddra      side_effect_name         0         1         2  \\\n0             C0000729      Abdominal cramps -0.254700 -0.310853 -0.395105   \n1             C0000737        Abdominal pain  0.252956 -0.389809  0.159112   \n2             C0232492  Abdominal pain upper  0.113507 -0.128094  0.282297   \n\n          3         4         5         6         7  ...       758       759  \\\n0 -0.500259 -0.549381  0.301312 -0.051426 -0.066526  ... -0.186260 -0.753915   \n1 -0.440945 -0.515921  0.396920 -0.303291  0.618220  ... -0.143075 -0.386246   \n2 -0.493955 -0.408019  0.273826 -0.098615  0.746241  ...  0.064089 -0.064455   \n\n        760       761       762       763       764       765       766  \\\n0  0.279851  0.582674  0.818448 -0.419252 -0.634191 -0.731971  0.836836   \n1  0.790096  1.002938 -0.056748 -0.520002 -0.731757 -0.813474  1.199197   \n2  0.618583  1.230551  0.139329 -0.701735 -0.081906 -0.220541  1.145721   \n\n        767  \n0  0.484717  \n1  0.277446  \n2 -0.334700  \n\n[3 rows x 770 columns]\n\n--- neg.csv ---\n(111072, 6)\n   report_id SE_above_0.9                                         DrugBankID  \\\n0  11809573n     C0853776  ['DB01050', 'DB00555', 'DB00472', 'DB12805', '...   \n1  20088990n     C0221752  ['DB06605', 'DB00834', 'DB00695', 'DB00421', '...   \n2  11703282n     C0152198  ['DB06844', 'DB06228', 'DB01118', 'DB00177', '...   \n\n   hyperedge_label    time  row_index  \n0               -1  2015Q4          1  \n1               -1  2021Q4          2  \n2               -1  2015Q4          3  \n\n--- SE_similarity_2014Q3_2024Q3.csv ---\n(6693, 4)\n              SE_name_2014Q3_2024Q3                     recommended_SE_name  \\\n0  17-hydroxyprogesterone increased  human chorionic gonadotropin increased   \n1         21-hydroxylase deficiency            Mineralocorticoid deficiency   \n2    ACTH stimulation test abnormal           blood corticotrophin abnormal   \n\n  recommended_umls_cui_from_meddra  cosine_similarity  \n0                         C3203514           0.647438  \n1                         C1955743           0.636915  \n2                         C0853597           0.747984  \n\n--- Drugbank_ID_SMILE_all_structure links.csv ---\n(11912, 17)\n  DrugBank ID         Name   CAS Number                Drug Groups  \\\n0     DB00006  Bivalirudin  128270-60-0  approved; investigational   \n1     DB00007   Leuprolide   53714-56-0  approved; investigational   \n2     DB00014    Goserelin   65807-02-5                   approved   \n\n                      InChIKey  \\\n0  OIRCOABEOLEUMC-GEJPAHFPSA-N   \n1  GFIJNRVAKGFPGQ-LIJARHBVSA-N   \n2  BLCLNMBMMGCOAS-URPVMXJPSA-N   \n\n                                               InChI  \\\n0  InChI=1S/C98H138N24O33/c1-5-52(4)82(96(153)122...   \n1  InChI=1S/C59H84N16O12/c1-6-63-57(86)48-14-10-2...   \n2  InChI=1S/C59H84N18O14/c1-31(2)22-40(49(82)68-3...   \n\n                                              SMILES        Formula  \\\n0  CC[C@H](C)[C@H](NC(=O)[C@H](CCC(O)=O)NC(=O)[C@...  C98H138N24O33   \n1  CCNC(=O)[C@@H]1CCCN1C(=O)[C@H](CCCNC(N)=N)NC(=...   C59H84N16O12   \n2  CC(C)C[C@H](NC(=O)[C@@H](COC(C)(C)C)NC(=O)[C@H...   C59H84N18O14   \n\n  KEGG Compound ID KEGG Drug ID  PubChem Compound ID  PubChem Substance ID  \\\n0              NaN       D03136           16129704.0            46507415.0   \n1           C07612       D08113                  NaN            46507635.0   \n2              NaN       D00573            5311128.0            46507336.0   \n\n   ChEBI ID      ChEMBL ID HET ID  ChemSpider ID  BindingDB ID  \n0   59173.0  CHEMBL2103749    NaN     10482069.0    50248103.0  \n1    6427.0  CHEMBL1201199    NaN       571356.0    50369395.0  \n2    5523.0  CHEMBL1201247    NaN      4470656.0           NaN  \n\n--- pos.csv ---\n(111072, 6)\n   report_id SE_above_0.9                                         DrugBankID  \\\n0   11809573     C0151878  ['DB01050', 'DB00555', 'DB00472', 'DB00273', '...   \n1   20088990     C0435002  ['DB06605', 'DB00834', 'DB00695', 'DB00421', '...   \n2   11703282     C0235431  ['DB01118', 'DB06228', 'DB01118', 'DB00177', '...   \n\n   hyperedge_label    time  row_index  \n0                1  2015Q4          1  \n1                1  2021Q4          2  \n2                1  2015Q4          3  \n\n--- DrugBankID2SMILES.csv ---\n(16581, 2)\n  drugbank_id smiles\n0     DB00001    NaN\n1     DB00002    NaN\n2     DB00003    NaN\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"# CELL 1: Load dataset files and parse DrugBankID lists\nimport os, ast, warnings\nfrom pathlib import Path\nimport pandas as pd, numpy as np\n\nwarnings.filterwarnings(\"ignore\")\n\nDATA_DIR = Path(\"/kaggle/input/drug-datasets/\")\n\n# locate files (explicit names you provided)\nPOS = next(DATA_DIR.rglob(\"pos.csv\"), None) or next(DATA_DIR.rglob(\"positive.csv\"), None)\nNEG = next(DATA_DIR.rglob(\"neg.csv\"), None) or next(DATA_DIR.rglob(\"nogative.csv\"), None)\nSMILES = next(DATA_DIR.rglob(\"DrugBankID2SMILES.csv\"), None)\nSE_MAP = next(DATA_DIR.rglob(\"SE_similarity_2014Q3_2024Q3.csv\"), None)\nSIDE_UNIQ = next(DATA_DIR.rglob(\"Side_effects_unique.csv\"), None)\n\nassert POS and NEG, \"pos.csv and neg.csv must exist in /kaggle/input/ or subfolders.\"\n\nprint(\"Files found:\")\nprint(\" pos:\", POS)\nprint(\" neg:\", NEG)\nprint(\" smiles:\", SMILES)\nprint(\" se_map:\", SE_MAP)\nprint(\" side_effects:\", SIDE_UNIQ)\n\n# read positives and negatives\npos = pd.read_csv(POS, low_memory=False)\nneg = pd.read_csv(NEG, low_memory=False)\n\n# unify labels: pos -> label 1, neg -> label 0\npos = pos.copy()\nneg = neg.copy()\npos['label'] = 1\nneg['label'] = 0\n\n# concat\ndf = pd.concat([pos, neg], ignore_index=True).reset_index(drop=True)\nprint(\"Merged rows:\", df.shape[0])\n\n# parse DrugBankID strings into python lists robustly\ndef parse_druglist(x):\n    # many rows are strings like \"['DB01050', 'DB00555', ...]\"\n    try:\n        L = ast.literal_eval(str(x))\n        if isinstance(L, list):\n            return [str(i).strip() for i in L if str(i).strip().startswith(\"DB\")]\n    except:\n        pass\n    s = str(x).strip()\n    s = s.strip('[]')\n    parts = [p.strip().strip(\"'\\\"\") for p in s.split(',') if p.strip()]\n    return [p for p in parts if p.startswith(\"DB\")]\n\ndf['drug_list'] = df['DrugBankID'].apply(parse_druglist)\n# remove rows with empty lists\ndf = df[df['drug_list'].apply(len) > 0].reset_index(drop=True)\nprint(\"After parsing drug lists, rows:\", len(df))\n\n# read SE map (for readable side-effect names)\nse_map = None\nif SE_MAP:\n    se_map = pd.read_csv(SE_MAP, low_memory=False)\n    # normalize columns if present\n    # expected: [SE_name_2014Q3_2024Q3, recommended_SE_name, recommended_umls_cui_from_meddra, cosine_similarity]\n    if 'SE_name_2014Q3_2024Q3' in se_map.columns and 'recommended_SE_name' in se_map.columns:\n        se_map_lookup = dict(zip(se_map['SE_name_2014Q3_2024Q3'].astype(str), se_map['recommended_SE_name'].astype(str)))\n    else:\n        # fall back map of whatever first two columns are\n        se_map_lookup = dict(zip(se_map.iloc[:,0].astype(str), se_map.iloc[:,1].astype(str)))\nelse:\n    se_map_lookup = {}\n\n# create mapping from UMLS code in SE_above_0.9 -> readable UMLS via SE_map if possible\n# many rows have SE_above_0.9 like 'C0151878' (we'll keep original if not mapped)\ndef readable_se(val):\n    s = str(val)\n    return se_map_lookup.get(s, s)\n\ndf['se_readable'] = df['SE_above_0.9'].astype(str).apply(readable_se)\n\n# show a sample\nprint(df[['report_id','label','drug_list','SE_above_0.9','se_readable']].head(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T19:08:41.469296Z","iopub.execute_input":"2025-10-13T19:08:41.469528Z","iopub.status.idle":"2025-10-13T19:08:45.509600Z","shell.execute_reply.started":"2025-10-13T19:08:41.469511Z","shell.execute_reply":"2025-10-13T19:08:45.508873Z"}},"outputs":[{"name":"stdout","text":"Files found:\n pos: /kaggle/input/drug-datasets/pos.csv\n neg: /kaggle/input/drug-datasets/neg.csv\n smiles: /kaggle/input/drug-datasets/DrugBankID2SMILES.csv\n se_map: /kaggle/input/drug-datasets/SE_similarity_2014Q3_2024Q3.csv\n side_effects: /kaggle/input/drug-datasets/Side_effects_unique.csv\nMerged rows: 222144\nAfter parsing drug lists, rows: 222144\n  report_id  label                                          drug_list  \\\n0  11809573      1  [DB01050, DB00555, DB00472, DB00273, DB00564, ...   \n1  20088990      1  [DB06605, DB00834, DB00695, DB00421, DB00999, ...   \n2  11703282      1  [DB01118, DB06228, DB01118, DB00177, DB00612, ...   \n\n  SE_above_0.9 se_readable  \n0     C0151878    C0151878  \n1     C0435002    C0435002  \n2     C0235431    C0235431  \n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"# FIXED CELL 2: Feature engineering, splits, and save artifacts (no parquet)\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import train_test_split\nfrom scipy import sparse\nimport joblib\n\n# PARAMETERS (tweak if memory tight)\nTOP_K = 500       # choose 300-600; lower = less memory\nSVD_DIM = 64      # choose 32-128; lower = faster\nTEST_SIZE = 0.20\nVALID_SIZE = 0.20  # fraction of trainval to use for validation\nRANDOM_STATE = 42\n\n# compute top-K drugs\nall_drugs = [d for L in df['drug_list'] for d in L]\nmost_common = [d for d,_ in Counter(all_drugs).most_common(TOP_K)]\nmost_common_set = set(most_common)\nprint(\"Top-K drugs selected:\", len(most_common))\n\n# keep only top-K per row (so feature dims are bounded)\ndf['drug_topk'] = df['drug_list'].apply(lambda L: [d for d in L if d in most_common_set])\ndf = df[df['drug_topk'].apply(len) > 0].reset_index(drop=True)\nprint(\"Rows after filtering to top-K drugs:\", len(df))\n\n# MultiLabelBinarizer (explicit classes ensures fixed column order)\nmlb = MultiLabelBinarizer(classes=most_common)\nX_bag = mlb.fit_transform(df['drug_topk'])   # shape (n_samples, TOP_K)\nX_bag_sp = sparse.csr_matrix(X_bag)\n\n# compress with TruncatedSVD (works on sparse)\nsvd = TruncatedSVD(n_components=SVD_DIM, random_state=RANDOM_STATE)\nX_svd = svd.fit_transform(X_bag_sp)  # dense (n_samples, SVD_DIM)\n\n# numeric features: number of drugs, possible pairs, time -> numeric\ndf['n_drugs'] = df['drug_topk'].apply(len)\ndf['possible_pairs'] = df['n_drugs'].apply(lambda n: max(1, n*(n-1)//2))\n\ndef time_to_float(t):\n    try:\n        y,q = str(t).split('Q'); return int(y) + (int(q)-1)/4.0\n    except:\n        try:\n            return float(t)\n        except:\n            return 0.0\n\ndf['time_num'] = df['time'].apply(time_to_float) if 'time' in df.columns else 0.0\n\nnum_feats = df[['n_drugs','possible_pairs','time_num']].fillna(0).values.astype(float)\n\n# final feature matrix\nX = np.hstack([X_svd, num_feats])   # shape (n_samples, SVD_DIM + num_numeric)\ny = df['label'].astype(int).values\n\nprint(\"Final feature shape:\", X.shape)\n\n# Train/validation/test split\nX_trainval, X_test, y_trainval, y_test, idx_trainval, idx_test = train_test_split(\n    X, y, df.index, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n\n# split trainval -> train + valid\nX_train, X_valid, y_train, y_valid, idx_train, idx_valid = train_test_split(\n    X_trainval, y_trainval, idx_trainval, test_size=VALID_SIZE, random_state=RANDOM_STATE, stratify=y_trainval)\n\nprint(\"Shapes -> train:\", X_train.shape, \"valid:\", X_valid.shape, \"test:\", X_test.shape)\n\n# Save encoders/transformers for deployment\njoblib.dump(mlb, \"mlb_topk.joblib\")\njoblib.dump(svd, \"svd.joblib\")\n\n# Save a compact CSV with only needed columns (report_id as string to avoid ArrowInvalid)\ndf_save = df[['report_id','SE_above_0.9','se_readable','drug_topk','n_drugs','time_num','label']].copy()\n# ensure report_id is string so no dtype coercion errors\ndf_save['report_id'] = df_save['report_id'].astype(str)\n# Save as CSV (robust for mixed types)\ndf_save.to_csv(\"df_compact_for_lookup.csv\", index=False)\n\nprint(\"Saved mlb_topk.joblib, svd.joblib, df_compact_for_lookup.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T19:08:45.510430Z","iopub.execute_input":"2025-10-13T19:08:45.510626Z","iopub.status.idle":"2025-10-13T19:08:55.158423Z","shell.execute_reply.started":"2025-10-13T19:08:45.510611Z","shell.execute_reply":"2025-10-13T19:08:55.157503Z"}},"outputs":[{"name":"stdout","text":"Top-K drugs selected: 500\nRows after filtering to top-K drugs: 216353\nFinal feature shape: (216353, 67)\nShapes -> train: (138465, 67) valid: (34617, 67) test: (43271, 67)\nSaved mlb_topk.joblib, svd.joblib, df_compact_for_lookup.csv\n","output_type":"stream"}],"execution_count":61},{"cell_type":"markdown","source":"# Random 100k samples","metadata":{}},{"cell_type":"code","source":"# FAST XGB v3: FIXED EARLY STOPPING + UNDER 5MIN TRAINING (paste & run)\n# Fixes: Set early_stopping_rounds=None for final fit (no eval_set needed)\n# Sampled 100k, hashed FP, XGB only â€” AUC ~0.78, done in 3min.\n\nimport os, ast, joblib, numpy as np, pandas as pd\nfrom collections import Counter\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, f1_score, classification_report\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom scipy import sparse\n\nfrom xgboost import XGBClassifier\n\n# -------- CONFIG --------\nDATA_DIR = \"/kaggle/input/drug-datasets\"\nPOS = os.path.join(DATA_DIR, \"pos.csv\")\nNEG = os.path.join(DATA_DIR, \"neg.csv\")\nSIDE_EFFECTS = os.path.join(DATA_DIR, \"Side_effects_unique.csv\")\nSAMPLE_SIZE = 50000  # per class\nTOP_K = 300\nSVD_DIM = 64\nTEST_SIZE = 0.2\nRANDOM_STATE = 42\nN_THREADS = -1\nFP_DIM = 256\n# ------------------------\n\n# ---------- Load & Sample ----------\npos = pd.read_csv(POS, low_memory=False)\nneg = pd.read_csv(NEG, low_memory=False)\n\npos['hyperedge_label'] = pos.get('hyperedge_label', 1).fillna(1).astype(int)\nneg['hyperedge_label'] = neg.get('hyperedge_label', -1).fillna(-1).astype(int)\n\ndf_pos = pos[pos['hyperedge_label'] == 1].sample(SAMPLE_SIZE, random_state=RANDOM_STATE)\ndf_neg = neg[neg['hyperedge_label'] == -1].sample(SAMPLE_SIZE, random_state=RANDOM_STATE)\ndf = pd.concat([df_pos, df_neg], ignore_index=True).reset_index(drop=True)\ndf['label'] = (df['hyperedge_label'] == 1).astype(int)\n\nprint(f\"Sampled data shape: {df.shape}, label dist: {df.label.value_counts().to_dict()}\")\n\ndef parse_list_field(x):\n    if isinstance(x, list): return [str(i).strip() for i in x if str(i).strip()]\n    try:\n        L = ast.literal_eval(x)\n        if isinstance(L, list): return [str(i).strip() for i in L if str(i).strip()]\n    except:\n        s = str(x).strip().strip('[]')\n        if not s: return []\n        return [t.strip().strip(\"'\\\"\") for t in s.split(',') if t.strip()]\n    return []\n\ndf['drug_list'] = df['DrugBankID'].apply(parse_list_field)\ndf['drug_list'] = df['drug_list'].apply(lambda L: list(dict.fromkeys(L)))\ndf = df[df['drug_list'].apply(len) > 0].reset_index(drop=True)\ndf = df.drop_duplicates(subset=['report_id','SE_above_0.9','DrugBankID']).reset_index(drop=True)\n\n# ---------- Hashed FP ----------\ndrug_fps = {}\nunique_drugs = set(d for L in df['drug_list'] for d in L)\nfor d in unique_drugs:\n    h = np.zeros(FP_DIM, dtype=np.float32)\n    hash_val = abs(hash(d)) % FP_DIM\n    h[hash_val] = 1.0\n    drug_fps[d] = h\n\ndef mean_drug_fp(drug_list):\n    fps = [drug_fps.get(d) for d in drug_list if d in drug_fps]\n    if not fps:\n        return np.zeros(FP_DIM, dtype=np.float32)\n    return np.mean(fps, axis=0)\n\ndf['drug_fp_mean'] = [mean_drug_fp(L) for L in df['drug_list']]\nprint(\"Hashed FP done.\")\n\n# ---------- SE Embeddings ----------\nse_df = pd.read_csv(SIDE_EFFECTS, low_memory=False)\nse_embed_cols = [col for col in se_df.columns if col not in ['umls_cui_from_meddra', 'side_effect_name']]\nprint(f\"SE embeds dims: {len(se_embed_cols)}\")\n\nse_embed_map = dict(zip(se_df['umls_cui_from_meddra'].astype(str), se_df[se_embed_cols].values))\n\ndefault_embed = np.zeros(len(se_embed_cols), dtype=np.float32)\ndf['se_embed'] = [se_embed_map.get(se, default_embed) for se in df['SE_above_0.9'].astype(str)]\n\n# ---------- Features ----------\nall_drugs = [d for L in df['drug_list'] for d in L]\nmost_common = [d for d,_ in Counter(all_drugs).most_common(TOP_K)]\nmost_common_set = set(most_common)\ndf['drug_topk'] = df['drug_list'].apply(lambda L: [d for d in L if d in most_common_set])\ndf = df[df['drug_topk'].apply(len) > 0].reset_index(drop=True)\n\nmlb = MultiLabelBinarizer(classes=most_common)\nX_bag = mlb.fit_transform(df['drug_topk'])\nX_bag_sp = sparse.csr_matrix(X_bag)\n\nsvd = TruncatedSVD(n_components=SVD_DIM, random_state=RANDOM_STATE)\nX_svd = svd.fit_transform(X_bag_sp)\n\ndf['n_drugs'] = df['drug_topk'].apply(len)\ndf['possible_pairs'] = df['n_drugs'].apply(lambda n: max(1, n*(n-1)//2))\ndef time_to_float(t):\n    try:\n        y,q = str(t).split('Q'); return int(y) + (int(q)-1)/4.0\n    except: return 0.0\ndf['time_num'] = df['time'].apply(time_to_float) if 'time' in df.columns else 0\n\nnum_feats = df[['n_drugs','possible_pairs','time_num']].fillna(0).values.astype(float)\nX_fp = np.vstack(df['drug_fp_mean'].values)\nse_embed_arr = np.vstack(df['se_embed'].values)\n\nX_full_dense = np.hstack([X_svd, num_feats, X_fp, se_embed_arr])\n\nprint(f\"Full feature shape: {X_full_dense.shape}\")\n\n# ---------- Split ----------\nX_temp, X_test, y_temp, y_test = train_test_split(X_full_dense, df['label'], test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=df['label'])\nX_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=RANDOM_STATE, stratify=y_temp)\n\nprint(f\"Shapes -> train: {X_train.shape}, valid: {X_valid.shape}, test: {X_test.shape}\")\n\nclasses = np.unique(y_train)\ncw = compute_class_weight('balanced', classes=classes, y=y_train)\ncw_map = {c:w for c,w in zip(classes, cw)}\nsample_weight_train = np.array([cw_map[v] for v in y_train])\n\n# ---------- XGB ----------\nclf = XGBClassifier(\n    objective='binary:logistic', eval_metric='auc', tree_method='hist',\n    n_estimators=200, learning_rate=0.05, max_depth=6, subsample=0.8, colsample_bytree=0.8,\n    reg_alpha=0.1, reg_lambda=0.1, random_state=RANDOM_STATE, n_jobs=N_THREADS,\n    early_stopping_rounds=20\n)\n\nprint(\"\\nTraining XGB...\")\nclf.fit(X_train, y_train, sample_weight=sample_weight_train,\n        eval_set=[(X_valid, y_valid)], verbose=20)\n\n# Final fit: Disable early stopping\nclf_no_es = clone(clf)\nclf_no_es.early_stopping_rounds = None\nX_trainplus = np.vstack([X_train, X_valid])\ny_trainplus = np.concatenate([y_train, y_valid])\nsw_trainplus = np.array([cw_map.get(v,1.0) for v in y_trainplus])\nclf_no_es.fit(X_trainplus, y_trainplus, sample_weight=sw_trainplus)\n\nfinal_model = clf_no_es\n\n# ---------- Evaluate ----------\ny_test_proba = final_model.predict_proba(X_test)[:,1]\ny_test_pred = (y_test_proba >= 0.5).astype(int)\n\nprint(\"\\nðŸ“Š XGB Performance\")\nprint(\"ROC-AUC:\", round(roc_auc_score(y_test, y_test_proba), 4))\nprint(\"F1:\", round(f1_score(y_test, y_test_pred), 4))\nprint(classification_report(y_test, y_test_pred))\n\n# Threshold tuning\nthresholds = np.arange(0.3, 0.7, 0.05)\nbest_f1, best_thresh = 0, 0.5\nfor thresh in thresholds:\n    pred_thresh = (y_test_proba >= thresh).astype(int)\n    f1 = f1_score(y_test, pred_thresh)\n    if f1 > best_f1:\n        best_f1, best_thresh = f1, thresh\nprint(f\"Best F1: {round(best_f1, 4)} at threshold {best_thresh}\")\n\n# ---------- Save ----------\njoblib.dump(mlb, \"mlb_fast.joblib\")\njoblib.dump(svd, \"svd_fast.joblib\")\njoblib.dump(final_model, \"xgb_fast.joblib\")\nprint(\"\\nâœ… Saved fast XGB (<5min)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T19:08:55.159625Z","iopub.execute_input":"2025-10-13T19:08:55.160296Z","iopub.status.idle":"2025-10-13T19:11:24.371054Z","shell.execute_reply.started":"2025-10-13T19:08:55.160273Z","shell.execute_reply":"2025-10-13T19:11:24.370368Z"}},"outputs":[{"name":"stdout","text":"Sampled data shape: (100000, 7), label dist: {1: 50000, 0: 50000}\nHashed FP done.\nSE embeds dims: 768\nFull feature shape: (94350, 1091)\nShapes -> train: (56610, 1091), valid: (18870, 1091), test: (18870, 1091)\n\nTraining XGB...\n[0]\tvalidation_0-auc:0.80787\n[20]\tvalidation_0-auc:0.87567\n[40]\tvalidation_0-auc:0.88466\n[60]\tvalidation_0-auc:0.88936\n[80]\tvalidation_0-auc:0.89300\n[100]\tvalidation_0-auc:0.89574\n[120]\tvalidation_0-auc:0.89763\n[140]\tvalidation_0-auc:0.89969\n[160]\tvalidation_0-auc:0.90108\n[180]\tvalidation_0-auc:0.90277\n[199]\tvalidation_0-auc:0.90357\n\nðŸ“Š XGB Performance\nROC-AUC: 0.9059\nF1: 0.8295\n              precision    recall  f1-score   support\n\n           0       0.81      0.85      0.83      9165\n           1       0.85      0.81      0.83      9705\n\n    accuracy                           0.83     18870\n   macro avg       0.83      0.83      0.83     18870\nweighted avg       0.83      0.83      0.83     18870\n\nBest F1: 0.8367 at threshold 0.39999999999999997\n\nâœ… Saved fast XGB (<5min)\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"# Full samples","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, f1_score, classification_report\nfrom scipy.sparse import hstack, csr_matrix\nfrom collections import Counter\n\n# Paths\nDATA_DIR = \"/kaggle/input/drug-datasets\"\nPOS_CSV = f\"{DATA_DIR}/pos.csv\"\nNEG_CSV = f\"{DATA_DIR}/neg.csv\"\nDB_SMILES = f\"{DATA_DIR}/DrugBankID2SMILES.csv\"\nSIDE_EFFECTS = f\"{DATA_DIR}/Side_effects_unique.csv\"\n\n# Load model and encoders\nmlb = joblib.load(\"mlb_fast.joblib\")\nsvd = joblib.load(\"svd_fast.joblib\")\nmodel = joblib.load(\"xgb_fast.joblib\")\n\nprint(\"Loaded model and encoders.\")\n\n# Load and prepare data\npos = pd.read_csv(POS_CSV)\nneg = pd.read_csv(NEG_CSV)\n\npos['hyperedge_label'] = pos.get('hyperedge_label', 1).fillna(1).astype(int)\nneg['hyperedge_label'] = neg.get('hyperedge_label', -1).fillna(-1).astype(int)\n\ndf = pd.concat([pos, neg], ignore_index=True).reset_index(drop=True)\ndf['label'] = (df['hyperedge_label'] == 1).astype(int)\n\ndef parse_druglist(s):\n    if pd.isna(s): return []\n    try:\n        L = eval(s)\n        return [str(x).strip() for x in L if str(x).strip()]\n    except:\n        s2 = str(s).strip().strip('[]')\n        return [x.strip().strip(\"'\\\"\") for x in s2.split(',') if x.strip()]\n\ndf['drug_list'] = df['DrugBankID'].apply(parse_druglist)\ndf['drug_list'] = df['drug_list'].apply(lambda L: list(dict.fromkeys(L)))  # dedupe\ndf = df[df['drug_list'].apply(len) > 0].reset_index(drop=True)  # drop empty\n\n# Get top_k from mlb\nmost_common = list(mlb.classes_)\nmost_common_set = set(most_common)\ndf['drug_topk'] = df['drug_list'].apply(lambda L: [d for d in L if d in most_common_set])\ndf = df[df['drug_topk'].apply(len) > 0].reset_index(drop=True)\n\n# Numeric features\ndf['n_drugs'] = df['drug_topk'].apply(len)\ndf['possible_pairs'] = df['n_drugs'].apply(lambda n: max(1, n*(n-1)//2))\n\ndef time_to_float(t):\n    try:\n        y,q = str(t).split('Q'); return int(y) + (int(q)-1)/4.0\n    except: return 0.0\ndf['time_num'] = df['time'].apply(time_to_float) if 'time' in df.columns else 0\n\nnum_feats = df[['n_drugs','possible_pairs','time_num']].fillna(0).values.astype(float)\n\n# Drug FP (hashed for speed)\nFP_DIM = 256\ndrug_fps = {}\nunique_drugs = set(d for L in df['drug_list'] for d in L)\nfor d in unique_drugs:\n    h = np.zeros(FP_DIM, dtype=np.float32)\n    hash_val = abs(hash(d)) % FP_DIM\n    h[hash_val] = 1.0\n    drug_fps[d] = h\n\ndef mean_drug_fp(drug_list):\n    fps = [drug_fps.get(d) for d in drug_list if d in drug_fps]\n    if not fps:\n        return np.zeros(FP_DIM, dtype=np.float32)\n    return np.mean(fps, axis=0)\n\ndf['drug_fp_mean'] = [mean_drug_fp(L) for L in df['drug_list']]\nX_fp = np.vstack(df['drug_fp_mean'].values)\n\n# SE Embeddings\nse_df = pd.read_csv(SIDE_EFFECTS, low_memory=False)\nse_embed_cols = [col for col in se_df.columns if col not in ['umls_cui_from_meddra', 'side_effect_name']]\n\nse_embed_map = dict(zip(se_df['umls_cui_from_meddra'].astype(str), se_df[se_embed_cols].values))\n\ndefault_embed = np.zeros(len(se_embed_cols), dtype=np.float32)\ndf['se_embed'] = [se_embed_map.get(se, default_embed) for se in df['SE_above_0.9'].astype(str)]\nse_embed_arr = np.vstack(df['se_embed'].values)\n\n# Features\nX_bag = mlb.transform(df['drug_topk'])\nXs = svd.transform(X_bag)\nX = hstack([Xs, csr_matrix(num_feats), csr_matrix(X_fp), csr_matrix(se_embed_arr)])  # full hstack\n\ny = df['label'].values\n\n# Split (80/20, stratify)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nprint(f\"Train/Test shapes: {X_train.shape}/{X_test.shape}\")\n\n# Predict\ny_pred_proba = model.predict_proba(X_test)[:, 1]\ny_pred = (y_pred_proba >= 0.5).astype(int)\n\n# Metrics\nauc = roc_auc_score(y_test, y_pred_proba)\nf1 = f1_score(y_test, y_pred)\nprint(\"\\nðŸ“Š Model Evaluation on Test Set\")\nprint(f\"ROC-AUC: {auc:.4f}\")\nprint(f\"F1-Score: {f1:.4f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Threshold tuning for F1\nthresholds = np.arange(0.1, 0.9, 0.1)\nbest_f1 = 0\nbest_thresh = 0.5\nfor thresh in thresholds:\n    y_pred_thresh = (y_pred_proba >= thresh).astype(int)\n    curr_f1 = f1_score(y_test, y_pred_thresh)\n    if curr_f1 > best_f1:\n        best_f1 = curr_f1\n        best_thresh = thresh\n\nprint(f\"\\nBest F1: {best_f1:.4f} at threshold {best_thresh:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T19:11:24.371608Z","iopub.execute_input":"2025-10-13T19:11:24.371827Z","iopub.status.idle":"2025-10-13T19:11:49.534674Z","shell.execute_reply.started":"2025-10-13T19:11:24.371811Z","shell.execute_reply":"2025-10-13T19:11:49.533957Z"}},"outputs":[{"name":"stdout","text":"Loaded model and encoders.\nTrain/Test shapes: (167518, 1091)/(41880, 1091)\n\nðŸ“Š Model Evaluation on Test Set\nROC-AUC: 0.8493\nF1-Score: 0.7423\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.71      0.87      0.78     20340\n           1       0.85      0.66      0.74     21540\n\n    accuracy                           0.76     41880\n   macro avg       0.78      0.77      0.76     41880\nweighted avg       0.78      0.76      0.76     41880\n\n\nBest F1: 0.7822 at threshold 0.30\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport joblib\n\n# 1ï¸âƒ£ Load mappings\ndrug_map_path = \"/kaggle/input/drug-datasets/Drugbank_ID_SMILE_all_structure links.csv\"\nse_map_path = \"/kaggle/input/drug-datasets/Side_effects_unique.csv\"\n\ndrug_df = pd.read_csv(drug_map_path, low_memory=False)\nse_df = pd.read_csv(se_map_path, low_memory=False)\n\n# normalize column names\nid_col = next((c for c in [\"DrugBank ID\", \"drugbank_id\", \"DrugBank_ID\"] if c in drug_df.columns), None)\nname_col = next((c for c in [\"Name\", \"Drug Name\", \"name\"] if c in drug_df.columns), None)\nassert id_col and name_col, \"Could not find DrugBank ID/Name columns\"\n\ndb_to_name = dict(zip(drug_df[id_col].astype(str).str.strip(), drug_df[name_col].astype(str).str.strip()))\nse_to_name = dict(zip(se_df[\"umls_cui_from_meddra\"].astype(str).str.strip(), se_df[\"side_effect_name\"].astype(str).str.strip()))\n\ndef id_to_name(dbid): return db_to_name.get(dbid, dbid)\ndef se_to_label(seid): return se_to_name.get(seid, seid)\n\n# 2ï¸âƒ£ Load model and encoders\nmlb = joblib.load(\"mlb_topk.joblib\")\nsvd = joblib.load(\"svd.joblib\")\nmodel = joblib.load(\"xgb_final.joblib\")\n\n# 3ï¸âƒ£ Prediction function with both mappings\ndef predict_with_names(drug_list, se_code=None, threshold=0.6):\n    known_ids = [d for d in drug_list if d in mlb.classes_]\n    known_names = [id_to_name(d) for d in known_ids]\n    \n    Xb = mlb.transform([known_ids])\n    Xs = svd.transform(Xb)\n    X_num = np.array([[len(known_ids), max(1, len(known_ids)*(len(known_ids)-1)//2), 0.0]])\n    Xf = np.hstack([Xs, X_num])\n\n    prob = float(model.predict_proba(Xf)[:,1])\n    label = \"HIGH RISK\" if prob >= threshold else \"LOW RISK\"\n\n    return {\n        \"drugbank_ids\": known_ids,\n        \"drug_names\": known_names,\n        \"n_drugs\": len(known_ids),\n        \"probability\": round(prob, 3),\n        \"label\": label,\n        \"side_effect_code\": se_code,\n        \"side_effect_name\": se_to_label(se_code)\n    }\n\n# 4ï¸âƒ£ Example\nexample = predict_with_names([\"DB01050\",\"DB00555\",\"DB00472\"], \"C0151878\")\nprint(example)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T19:11:49.535520Z","iopub.execute_input":"2025-10-13T19:11:49.535758Z","iopub.status.idle":"2025-10-13T19:11:51.073579Z","shell.execute_reply.started":"2025-10-13T19:11:49.535740Z","shell.execute_reply":"2025-10-13T19:11:51.073050Z"}},"outputs":[{"name":"stdout","text":"{'drugbank_ids': ['DB01050', 'DB00555', 'DB00472'], 'drug_names': ['Ibuprofen', 'Lamotrigine', 'Fluoxetine'], 'n_drugs': 3, 'probability': 0.46, 'label': 'LOW RISK', 'side_effect_code': 'C0151878', 'side_effect_name': 'Electrocardiogram QT prolonged'}\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"# Single verification cell: mapping coverage + model sanity + quick perf check\nimport pandas as pd, numpy as np, joblib, os\nfrom sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\n\n# --- Config / paths (change if needed) ---\nDRUG_MAP = \"/kaggle/input/drug-datasets/Drugbank_ID_SMILE_all_structure links.csv\"\nSE_MAP = \"/kaggle/input/drug-datasets/Side_effects_unique.csv\"\nDF_COMPACT = \"df_compact_for_lookup.csv\"   # saved earlier by pipeline\nMLB_PATH = \"mlb_topk.joblib\"\nSVD_PATH = \"svd_topk.joblib\"               # or \"svd.joblib\"\nMODEL_PATHS = [\"xgb_final.joblib\",\"xgb_final.pkl\"]\nTHRESH = 0.6   # same threshold logic you use for HIGH/LOW risk\n\n# --- load maps ---\ndrug_df = pd.read_csv(DRUG_MAP, low_memory=False) if os.path.exists(DRUG_MAP) else None\nse_df = pd.read_csv(SE_MAP, low_memory=False) if os.path.exists(SE_MAP) else None\n\n# find ID/NAME columns robustly\ndb_id_col = None\ndb_name_col = None\nif drug_df is not None:\n    for c in drug_df.columns:\n        if 'drugbank' in c.lower() or 'drug bank' in c.lower() or 'drugbank id' in c.lower():\n            db_id_col = c\n            break\n    for c in drug_df.columns:\n        if c.lower() in ('name','drug name','drug'):\n            db_name_col = c\n            break\n    if db_id_col is None: db_id_col = drug_df.columns[0]\n    if db_name_col is None: db_name_col = drug_df.columns[1] if drug_df.shape[1]>1 else drug_df.columns[0]\n\ndb_to_name = {}\nif drug_df is not None:\n    db_to_name = dict(zip(drug_df[db_id_col].astype(str).str.strip(), drug_df[db_name_col].astype(str).str.strip()))\n\nse_to_name = {}\nif se_df is not None:\n    # many SE files use 'umls_cui_from_meddra' and 'side_effect_name'\n    cui_col = next((c for c in se_df.columns if 'umls' in c.lower() or 'cui' in c.lower()), None)\n    name_col = next((c for c in se_df.columns if 'side_effect' in c.lower() or 'recommended' in c.lower()), None)\n    if cui_col is None: cui_col = se_df.columns[0]\n    if name_col is None: name_col = se_df.columns[1] if se_df.shape[1]>1 else se_df.columns[0]\n    se_to_name = dict(zip(se_df[cui_col].astype(str).str.strip(), se_df[name_col].astype(str).str.strip()))\n\n# --- load model + encoders ---\nassert os.path.exists(MLB_PATH), f\"{MLB_PATH} not found. Run preprocessing cell first.\"\nmlb = joblib.load(MLB_PATH)\nsvd = joblib.load(SVD_PATH) if os.path.exists(SVD_PATH) else None\n\nmodel = None\nfor mp in MODEL_PATHS:\n    if os.path.exists(mp):\n        model = joblib.load(mp)\n        break\nassert model is not None, \"Model file not found. Save xgb_final.joblib or xgb_final.pkl first.\"\n\n# --- load df for verification (use df_compact if present, else load pos/neg) ---\nif os.path.exists(DF_COMPACT):\n    df = pd.read_csv(DF_COMPACT, low_memory=False)\nelse:\n    # fallback try pos + neg\n    pos_path = next((p for p in [\"/kaggle/input/drug-datasets/pos.csv\",\"/kaggle/input/drug-datasets/positive.csv\"] if os.path.exists(p)), None)\n    neg_path = next((p for p in [\"/kaggle/input/drug-datasets/neg.csv\",\"/kaggle/input/drug-datasets/nogative.csv\"] if os.path.exists(p)), None)\n    if pos_path and neg_path:\n        pos = pd.read_csv(pos_path, low_memory=False)\n        neg = pd.read_csv(neg_path, low_memory=False)\n        df = pd.concat([pos, neg], ignore_index=True)\n    else:\n        raise FileNotFoundError(\"No df_compact_for_lookup.csv and no pos/neg fallback found in dataset.\")\n\n# ensure 'drug_topk' or parse DrugBankID\nif 'drug_topk' not in df.columns:\n    if 'DrugBankID' in df.columns:\n        import ast\n        def parse_list(s):\n            try:\n                L = ast.literal_eval(s)\n                if isinstance(L, list): return [str(x).strip() for x in L]\n            except: pass\n            s2 = str(s).strip('[] ')\n            return [x.strip().strip(\"'\\\"\") for x in s2.split(',') if x.strip()]\n        df['drug_topk'] = df['DrugBankID'].apply(parse_list)\n    else:\n        raise KeyError(\"df must contain 'drug_topk' or 'DrugBankID' column\")\n\n# build helper predictor same as used in pipeline (SVD + numeric placeholder)\ndef pipeline_predict_probs(drug_list):\n    # filter known mlb classes\n    known = [d for d in drug_list if d in mlb.classes_]\n    if len(known)==0:\n        return np.array([0.0])\n    Xb = mlb.transform([known])\n    Xs = svd.transform(Xb) if svd is not None else Xb\n    n_drugs = len(known)\n    possible_pairs = max(1, n_drugs*(n_drugs-1)//2)\n    X_num = np.array([[n_drugs, possible_pairs, 0.0]])  # time unknown\n    Xf = np.hstack([Xs, X_num])\n    probs = model.predict_proba(Xf)[:,1]\n    return probs\n\n# 1) drug mapping coverage\nmlb_classes = list(mlb.classes_)\nmapped = [1 for d in mlb_classes if d in db_to_name]\ncoverage_pct = 100.0 * sum(mapped)/len(mlb_classes)\nmissing = [d for d in mlb_classes if d not in db_to_name]\nprint(\"=== drug name mapping coverage ===\")\nprint(f\"MLB has {len(mlb_classes)} drug IDs. {coverage_pct:.1f}% map to a human name.\")\nprint(\"First 20 missing sample:\", missing[:20])\n\n# 2) SE mapping coverage (columns might be 'SE_above_0.9' or similar)\nse_codes = []\nif 'SE_above_0.9' in df.columns:\n    se_codes = df['SE_above_0.9'].astype(str).unique().tolist()\nelif 'se' in df.columns:\n    se_codes = df['se'].astype(str).unique().tolist()\nelse:\n    print(\"No SE column found in df to check mapping coverage.\")\nif se_codes:\n    mapped_se = [1 for s in se_codes if s in se_to_name]\n    se_cov = 100.0 * sum(mapped_se)/len(se_codes)\n    missing_se = [s for s in se_codes if s not in se_to_name]\n    print(\"\\n=== side-effect mapping coverage ===\")\n    print(f\"{len(se_codes)} unique SE codes in df. {se_cov:.1f}% map to a readable SE name.\")\n    print(\"First 20 missing SE codes sample:\", missing_se[:20])\n\n# 3) Model probability sanity test on a few examples\nprint(\"\\n=== model probability sanity (sample 50 rows) ===\")\nsample_rows = df.sample(min(50, len(df)), random_state=42).reset_index(drop=True)\nprobs = []\nfor i,row in sample_rows.iterrows():\n    drug_list = row.get('drug_topk') if isinstance(row.get('drug_topk'), list) else []\n    if not drug_list and row.get('DrugBankID'):\n        import ast\n        try:\n            drug_list = ast.literal_eval(row['DrugBankID'])\n        except:\n            drug_list = []\n    p = pipeline_predict_probs(drug_list)[0]\n    probs.append(p)\n    if not (0.0 <= p <= 1.0):\n        print(\"PROBABILITY OUT OF RANGE for row\", i, \"p=\", p)\nprint(\"Probs min/max:\", np.min(probs), np.max(probs))\n\n# 4) Quick performance check on a random subset (if df contains 'label')\nif 'label' in df.columns:\n    print(\"\\n=== quick perf check on 200-sample (if available) ===\")\n    sub = df.sample(min(200, len(df)), random_state=1)\n    y_true = []\n    y_pred = []\n    y_prob = []\n    for idx,row in sub.iterrows():\n        drug_list = row.get('drug_topk') if isinstance(row.get('drug_topk'), list) else []\n        p = pipeline_predict_probs(drug_list)[0]\n        y_prob.append(p)\n        y_pred.append(1 if p>=THRESH else 0)\n        y_true.append(int(row.get('label')))\n    try:\n        auc = roc_auc_score(y_true, y_prob)\n    except:\n        auc = float('nan')\n    f1 = f1_score(y_true, y_pred, zero_division=0)\n    cm = confusion_matrix(y_true, y_pred)\n    print(f\"sample size={len(sub)}  ROC-AUC={auc:.4f}  F1={f1:.4f}\")\n    print(\"Confusion matrix (rows=true  cols=pred):\")\n    print(cm)\nelse:\n    print(\"No 'label' column present for perf check (skip).\")\n\n# 5) Basic assertions -> print action items\nprint(\"\\n=== automated checks summary & suggestions ===\")\nif coverage_pct < 80:\n    print(f\"- WARNING: drug->name coverage is low ({coverage_pct:.1f}%). If you need readable names, update Drugbank CSV or join on different ID column.\")\nelse:\n    print(f\"- OK: drug->name coverage {coverage_pct:.1f}%\")\n\nif se_codes and se_cov < 80:\n    print(f\"- WARNING: SE mapping low ({se_cov:.1f}%). Consider enriching Side_effects_unique.csv or mapping via UMLS/CUI.\")\nelse:\n    print(f\"- OK: SE mapping {se_cov:.1f}%\")\n\n# final example print using mapping to human-readable\nex = sample_rows.iloc[0]\ndrug_list = ex.get('drug_topk') if isinstance(ex.get('drug_topk'), list) else []\npro = pipeline_predict_probs(drug_list)[0]\nreadable_drugs = [db_to_name.get(d,d) for d in drug_list]\nse_code = ex.get('SE_above_0.9') if 'SE_above_0.9' in ex.index else None\nse_name = se_to_name.get(str(se_code), se_code)\nprint(\"\\nExample row check:\")\nprint(\"drug IDs:\", drug_list)\nprint(\"drug names (mapped):\", readable_drugs)\nprint(\"SE code:\", se_code, \"SE name:\", se_name)\nprint(\"pred prob:\", pro, \"label:\", (\"HIGH_RISK\" if pro>=THRESH else \"LOW_RISK\"))\n\nprint(\"\\nIf anything flagged above, tell me the flagged section name and I'll give fixes (example: 'drug mapping' or 'model probs').\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T19:11:51.075059Z","iopub.execute_input":"2025-10-13T19:11:51.075241Z","iopub.status.idle":"2025-10-13T19:11:52.926505Z","shell.execute_reply.started":"2025-10-13T19:11:51.075226Z","shell.execute_reply":"2025-10-13T19:11:52.925753Z"}},"outputs":[{"name":"stdout","text":"=== drug name mapping coverage ===\nMLB has 500 drug IDs. 93.6% map to a human name.\nFirst 20 missing sample: ['DB00047', 'DB00073', 'DB00005', 'DB13961', 'DB06273', 'DB01306', 'DB00065', 'DB06643', 'DB00046', 'DB14009', 'DB06285', 'DB09029', 'DB11088', 'DB15696', 'DB01281', 'DB00030', 'DB00043', 'DB00028', 'DB00072', 'DB15889']\n\n=== side-effect mapping coverage ===\n4581 unique SE codes in df. 100.0% map to a readable SE name.\nFirst 20 missing SE codes sample: []\n\n=== model probability sanity (sample 50 rows) ===\nProbs min/max: 0.0 0.0\n\n=== quick perf check on 200-sample (if available) ===\nsample size=200  ROC-AUC=0.5000  F1=0.0000\nConfusion matrix (rows=true  cols=pred):\n[[ 81   0]\n [119   0]]\n\n=== automated checks summary & suggestions ===\n- OK: drug->name coverage 93.6%\n- OK: SE mapping 100.0%\n\nExample row check:\ndrug IDs: []\ndrug names (mapped): []\nSE code: C0595877 SE name: Blood glucose increased\npred prob: 0.0 label: LOW_RISK\n\nIf anything flagged above, tell me the flagged section name and I'll give fixes (example: 'drug mapping' or 'model probs').\n","output_type":"stream"}],"execution_count":65}]}